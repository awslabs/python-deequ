{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d9f38cf-e24a-4854-8027-09414874fb35",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Synchronising Computed Metrics in a MetricsRepository to a json file stored on DBFS\n",
    "\n",
    "PyDeequ allows us to persist the metrics we computed on dataframes in a so-called MetricsRepository. In the following example, we showcase repository json file managed by python-deequ on DBFS. This can be especially usefull:\n",
    "- For python-deequ application migration,\n",
    "- To manage MetricsRepository json on the application side application,\n",
    "- To enable explainability and analytics using MetricsRepository json.\n",
    "\n",
    "Note: As of 1.1.0 release of Python Deequ release initialising repository json as FileSystemMetricsRepository is the only way to run validations on historical metrics. InMemoryMetricsRepository does not support initialising from historical metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d31f7330-f71c-4a6b-80d0-852e3fee833c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 0) Set file location for metrics repository\n",
    "Write repository file using File API Format but provide Spark API Format to [FileSystemMetricsRepository](https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/repository/fs/FileSystemMetricsRepository.scala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed4115df-bf05-42ad-8feb-3e9ecf17e470",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metrics_file = '/table_xyz_pydeequ_metrics_repository.json'\n",
    "metrics_file_api =f\"/dbfs/dbfs{metrics_file}\"\n",
    "metrics_spark_api =f\"dbfs:/dbfs{metrics_file}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71833639-88d8-4151-8011-d5d659253e00",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1) Create json - that stores historical metrics\n",
    "\n",
    "This json structure is retrived from a previos pydeequ run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bf992c7-009a-4bef-9bb8-c3645870a610",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(metrics_file_api, \"w\", encoding='utf-8') as file:\n",
    "  file.write(\"\"\"\n",
    "  [\n",
    "    {\n",
    "      \"resultKey\": { \"dataSetDate\": 1702836503289, \"tags\": {} },\n",
    "      \"analyzerContext\": {\n",
    "        \"metricMap\": [\n",
    "          {\n",
    "            \"analyzer\": {\n",
    "              \"analyzerName\": \"Mean\",\n",
    "              \"column\": \"age\"\n",
    "            },\n",
    "            \"metric\": {\n",
    "              \"metricName\": \"DoubleMetric\",\n",
    "              \"entity\": \"Column\",\n",
    "              \"instance\": \"age\",\n",
    "              \"name\": \"Mean\",\n",
    "              \"value\": 32\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19d86aa3-a7d7-43d7-9a6a-a7f1073c2610",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 1.1) Validate the file is written to DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9c997a9-4917-4de5-8b8f-d0c6990baaca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n  [\r\n    {\r\n      \"resultKey\": { \"dataSetDate\": 1702836503289, \"tags\": {} },\r\n      \"analyzerContext\": {\r\n        \"metricMap\": [\r\n          {\r\n            \"analyzer\": {\r\n              \"analyzerName\": \"Mean\",\r\n              \"column\": \"age\"\r\n            },\r\n            \"metric\": {\r\n              \"metricName\": \"DoubleMetric\",\r\n              \"entity\": \"Column\",\r\n              \"instance\": \"age\",\r\n              \"name\": \"Mean\",\r\n              \"value\": 32\r\n            }\r\n          }\r\n        ]\r\n      }\r\n    }\r\n  ]"
     ]
    }
   ],
   "source": [
    "!cat /dbfs/dbfs/table_xyz_pydeequ_metrics_repository.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb162f44-4f97-43bf-804a-7256cc4dd4cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2) Initiate FileSystemMetricsRepository with underlying file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e2e05b0-45ac-4cfa-bc7b-7155c895680d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pydeequ.repository import FileSystemMetricsRepository\n",
    "\n",
    "repository = FileSystemMetricsRepository(spark, metrics_spark_api)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53716975-d2ed-4dc4-9f5f-c0805c2d9f67",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3) Run anomaly checks on new data but also using underlying file with historical metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d3984da-2324-4a5e-aa07-2d05ead562c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pydeequ.repository import ResultKey\n",
    "from pydeequ.verification import VerificationSuite\n",
    "from pydeequ.anomaly_detection import RelativeRateOfChangeStrategy\n",
    "from pydeequ.analyzers import Mean\n",
    "\n",
    "COLUMN_NAME = \"age\"\n",
    "\n",
    "df = spark.createDataFrame([{COLUMN_NAME:19},{COLUMN_NAME:21}])\n",
    "\n",
    "verification_suite = (\n",
    "    VerificationSuite(spark)\n",
    "        .onData(df)\n",
    "        .useRepository(repository)\n",
    "        .saveOrAppendResult(\n",
    "            ResultKey(\n",
    "                spark, \n",
    "                ResultKey.current_milli_time()\n",
    "            )\n",
    "        )\n",
    "        .addAnomalyCheck(\n",
    "            RelativeRateOfChangeStrategy(\n",
    "                maxRateDecrease=0.8,\n",
    "                maxRateIncrease=1.2\n",
    "            ), \n",
    "            Mean(COLUMN_NAME)\n",
    "        )\n",
    "    )\n",
    "results = verification_suite.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "222a856f-716c-47bc-be14-1506de64f8d5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 3.1) Validate that historical metrics were taken into consideration when calculating anomaly\n",
    "\n",
    "New data age mean is 20, while old data age average is 30. RelativeRateOfChangeStrategy should fails as accepted rate of change is +/-20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c43827c-68f2-406c-814d-951353a173bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>check</th><th>check_level</th><th>check_status</th><th>constraint</th><th>constraint_status</th><th>constraint_message</th></tr></thead><tbody><tr><td>Anomaly check for Mean(age,None)</td><td>Warning</td><td>Warning</td><td>AnomalyConstraint(Mean(age,None))</td><td>Failure</td><td>Value: 20.0 does not meet the constraint requirement!</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Anomaly check for Mean(age,None)",
         "Warning",
         "Warning",
         "AnomalyConstraint(Mean(age,None))",
         "Failure",
         "Value: 20.0 does not meet the constraint requirement!"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "check",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "check_level",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "check_status",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "constraint",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "constraint_status",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "constraint_message",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.checkResultsAsDataFrame(spark_session=spark, verificationResult=results).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4385b496-0cdf-430e-93d2-46ff6f26bf78",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 4) Validate that repository json is updated after VerificationSuite run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68d72b50-e7c2-4527-88d0-3ddc8d686e86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[63]: [{'resultKey': {'dataSetDate': 1702836503289, 'tags': {}},\n  'analyzerContext': {'metricMap': [{'analyzer': {'analyzerName': 'Mean',\n      'column': 'age'},\n     'metric': {'metricName': 'DoubleMetric',\n      'entity': 'Column',\n      'instance': 'age',\n      'name': 'Mean',\n      'value': 32.0}}]}},\n {'resultKey': {'dataSetDate': 1704554941399, 'tags': {}},\n  'analyzerContext': {'metricMap': [{'analyzer': {'analyzerName': 'Mean',\n      'column': 'age'},\n     'metric': {'metricName': 'DoubleMetric',\n      'entity': 'Column',\n      'instance': 'age',\n      'name': 'Mean',\n      'value': 20.0}}]}}]"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(metrics_file_api, \"r\", encoding=\"utf-8\") as file:\n",
    "    repository_str = file.read()\n",
    "\n",
    "json.loads(repository_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27207de9-faf8-4842-b564-ac940807d465",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pydeequ - FileSystemMetricsRepository sync - stand alone example",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
